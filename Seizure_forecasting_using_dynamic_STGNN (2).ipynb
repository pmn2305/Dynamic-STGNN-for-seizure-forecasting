{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mne pyedflib tqdm\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qky3J53KfNQO",
        "outputId": "8dd26752-3bbc-41aa-e9fc-eef0b9fd3362"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.10.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyedflib\n",
            "  Downloading pyedflib-0.1.42-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.10.5)\n",
            "Downloading mne-1.10.2-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyedflib-0.1.42-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyedflib, mne\n",
            "Successfully installed mne-1.10.2 pyedflib-0.1.42\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_scatter-2.1.2%2Bpt22cu118-cp312-cp312-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt22cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_sparse-0.6.18%2Bpt22cu118-cp312-cp312-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt22cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_cluster-1.6.3%2Bpt22cu118-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt22cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu118.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt22cu118-cp312-cp312-linux_x86_64.whl (902 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m902.1/902.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt22cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "import mne, csv, pathlib\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import skew, kurtosis\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZZIRXE1fIwi",
        "outputId": "c39d5799-e136-49f7-c0b0-2bfc297b8112"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7xbUg43OVHw",
        "outputId": "814b4ba0-84f9-4edd-f7ea-3422e5860314"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLfD6Oi3dP9o",
        "outputId": "afdf4a33-91f9-4498-febb-a9d9b1627ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Found EDF files: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1824363789.py:114: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  bp = lambda lo, hi: np.trapz(Pxx[(f>=lo)&(f<=hi)], f[(f>=lo)&(f<=hi)]) if np.any((f>=lo)&(f<=hi)) else 0.0\n",
            "files:   2%|▏         | 1/42 [01:25<58:19, 85.36s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:   5%|▍         | 2/42 [02:43<54:15, 81.39s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:   7%|▋         | 3/42 [04:01<51:39, 79.47s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  10%|▉         | 4/42 [05:18<49:49, 78.68s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  12%|█▏        | 5/42 [06:44<50:01, 81.12s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  14%|█▍        | 6/42 [08:06<48:55, 81.55s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  17%|█▋        | 7/42 [09:26<47:14, 80.99s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  19%|█▉        | 8/42 [10:47<45:59, 81.17s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  21%|██▏       | 9/42 [12:09<44:44, 81.35s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  24%|██▍       | 10/42 [13:28<43:03, 80.74s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  26%|██▌       | 11/42 [14:49<41:36, 80.54s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  29%|██▊       | 12/42 [16:12<40:46, 81.55s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  31%|███       | 13/42 [17:32<39:07, 80.96s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  33%|███▎      | 14/42 [18:52<37:35, 80.55s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  36%|███▌      | 15/42 [20:10<35:53, 79.75s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  38%|███▊      | 16/42 [21:28<34:24, 79.41s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  40%|████      | 17/42 [22:47<32:57, 79.10s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  43%|████▎     | 18/42 [24:04<31:26, 78.59s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  45%|████▌     | 19/42 [25:23<30:10, 78.70s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  48%|████▊     | 20/42 [26:26<27:06, 73.94s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  50%|█████     | 21/42 [27:44<26:18, 75.19s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  52%|█████▏    | 22/42 [29:05<25:40, 77.03s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  55%|█████▍    | 23/42 [30:25<24:41, 77.98s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  57%|█████▋    | 24/42 [31:46<23:39, 78.83s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  60%|█████▉    | 25/42 [33:06<22:24, 79.10s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  62%|██████▏   | 26/42 [33:56<18:44, 70.28s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  64%|██████▍   | 27/42 [34:09<13:17, 53.19s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  67%|██████▋   | 28/42 [35:31<14:24, 61.77s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  69%|██████▉   | 29/42 [36:53<14:44, 68.04s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  71%|███████▏  | 30/42 [38:13<14:16, 71.39s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  74%|███████▍  | 31/42 [39:31<13:29, 73.63s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  76%|███████▌  | 32/42 [40:51<12:32, 75.30s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  79%|███████▊  | 33/42 [42:10<11:28, 76.46s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  81%|████████  | 34/42 [43:29<10:17, 77.14s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  83%|████████▎ | 35/42 [44:49<09:07, 78.23s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  86%|████████▌ | 36/42 [46:11<07:55, 79.28s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  88%|████████▊ | 37/42 [47:30<06:36, 79.24s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  90%|█████████ | 38/42 [48:49<05:16, 79.13s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  93%|█████████▎| 39/42 [50:07<03:56, 78.91s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  95%|█████████▌| 40/42 [51:26<02:37, 78.78s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rfiles:  98%|█████████▊| 41/42 [52:47<01:19, 79.33s/it]/tmp/ipython-input-1824363789.py:69: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "files: 100%|██████████| 42/42 [54:07<00:00, 77.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences: 28929 | Pos: 420 | Neg: 28509\n",
            "Train sequences: 22497 Test sequences: 6432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os, glob, random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "import mne, csv, pathlib, re\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import skew, kurtosis\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch.utils.data import DataLoader as TorchDataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/chb_data\"   # your CHB folder\n",
        "SUBJECT = \"chb01\"                               # subject subfolder\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "WIN_SECS = 10\n",
        "STEP_SECS = 5\n",
        "SEQ_LEN = 4\n",
        "# Use top-k edges per node instead of hard thresholding for stability\n",
        "TOP_K = 12\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 12\n",
        "LR = 3e-4\n",
        "\n",
        "# Forecasting specifics\n",
        "PRE_SECS = 300        # preictal horizon in seconds\n",
        "EXCLUDE_ICTAL = True  # skip ictal windows\n",
        "SF_TARGET = 128       # target sampling freq used in resample()\n",
        "\n",
        "# Aug / robustness\n",
        "CHANNEL_DROPOUT_P = 0.05   # channel dropout during training\n",
        "LABEL_DILATION_WINDOWS = 1 # expand positive labels +- windows (0 = none)\n",
        "SOFT_LABEL_TAU = 120       # controls decay in soft label\n",
        "\n",
        "def read_seizure_events_from_summary(fpath):\n",
        "    fpath = Path(fpath)\n",
        "    subj_dir = fpath.parent\n",
        "    # find any *_summary.txt or similar\n",
        "    candidates = [p for p in subj_dir.iterdir() if re.search(r'-summary', p.name, re.IGNORECASE)]\n",
        "    if not candidates:\n",
        "        # no summary found (return empty)\n",
        "        return []\n",
        "    summary_path = candidates[0]\n",
        "    events = []\n",
        "    current_file = None\n",
        "    with open(summary_path, \"r\", errors=\"ignore\") as fh:\n",
        "        lines = [ln.strip() for ln in fh if ln.strip()]\n",
        "    for i, line in enumerate(lines):\n",
        "        if line.lower().startswith(\"file name:\"):\n",
        "            current_file = line.split(\":\",1)[1].strip()\n",
        "        elif \"seizure start time\" in line.lower() and current_file == fpath.name:\n",
        "            start_match = re.findall(r\"[\\d\\.]+\", line)\n",
        "            start = float(start_match[0]) if start_match else None\n",
        "            dur = 0.0\n",
        "            # look ahead for end time\n",
        "            if i+1 < len(lines) and \"seizure end time\" in lines[i+1].lower():\n",
        "                end_match = re.findall(r\"[\\d\\.]+\", lines[i+1])\n",
        "                if end_match and start is not None:\n",
        "                    end = float(end_match[0]); dur = end - start\n",
        "            if start is not None:\n",
        "                events.append((start, dur))\n",
        "    return events\n",
        "\n",
        "def load_eeg(fpath):\n",
        "    raw = mne.io.read_raw_edf(fpath, preload=True, verbose=False)\n",
        "    raw.pick_types(eeg=True)\n",
        "    raw.resample(SF_TARGET)  # downsample to target SF\n",
        "    sf = int(raw.info[\"sfreq\"])\n",
        "    data = raw.get_data()\n",
        "    return raw, data, sf\n",
        "\n",
        "# soft preictal probability (smooth label)\n",
        "def soft_label(window_end_sec, seizure_onsets):\n",
        "    if len(seizure_onsets) == 0:\n",
        "        return 0.0\n",
        "    dists = [max(0.0, onset - window_end_sec) for onset in seizure_onsets]\n",
        "    d = min(dists)\n",
        "    if d < PRE_SECS:\n",
        "        return float(np.exp(-(d**2) / (SOFT_LABEL_TAU**2)))\n",
        "    return 0.0\n",
        "\n",
        "# label dilation (expand positives by k windows on both sides)\n",
        "def dilate_labels_binary(y_windows, k):\n",
        "    if k <= 0:\n",
        "        return y_windows\n",
        "    out = y_windows.copy()\n",
        "    pos = np.where(y_windows==1)[0]\n",
        "    for i in pos:\n",
        "        lo = max(0, i-k); hi = min(len(y_windows), i+k+1)\n",
        "        out[lo:hi] = 1\n",
        "    return out\n",
        "\n",
        "# channel dropout augmentation for data robustness (applied at training graph time)\n",
        "def channel_dropout(seg, p=0.05):\n",
        "    seg = seg.copy()\n",
        "    C = seg.shape[0]\n",
        "    mask = (np.random.rand(C) > p).astype(float)\n",
        "    return seg * mask[:,None]\n",
        "\n",
        "# ----------------- Feature & graph construction (stable top-k) -----------------\n",
        "def extract_features(eeg_segment, sf):\n",
        "    feats = []\n",
        "    for ch in eeg_segment:\n",
        "        mean_v = ch.mean()\n",
        "        std_v = ch.std()\n",
        "        sk = skew(ch)\n",
        "        kurt = kurtosis(ch)\n",
        "        # band powers using simple welch\n",
        "        f, Pxx = welch(ch, fs=sf, nperseg=max(128, sf))\n",
        "        bp = lambda lo, hi: np.trapz(Pxx[(f>=lo)&(f<=hi)], f[(f>=lo)&(f<=hi)]) if np.any((f>=lo)&(f<=hi)) else 0.0\n",
        "        bands = [bp(0.5,4), bp(4,8), bp(8,13), bp(13,30), bp(30,70)]\n",
        "        feats.append([mean_v, std_v, float(sk), float(kurt)] + [float(b) for b in bands])\n",
        "    return np.array(feats, dtype=np.float32)\n",
        "\n",
        "def connectivity_matrix(eeg_segment):\n",
        "    \"\"\"Absolute correlation matrix with diagonal zeroed.\"\"\"\n",
        "    corr = np.corrcoef(eeg_segment)\n",
        "    corr = np.nan_to_num(np.abs(corr))\n",
        "    np.fill_diagonal(corr, 0)\n",
        "    return corr\n",
        "\n",
        "def build_graph(seg, label, sf, top_k=TOP_K):\n",
        "    \"\"\"Top-k edges per node (keeps weights) -> returns torch_geometric.Data.\"\"\"\n",
        "    x = extract_features(seg, sf)\n",
        "    A = connectivity_matrix(seg)\n",
        "    edges = []\n",
        "    weights = []\n",
        "    n = A.shape[0]\n",
        "    for i in range(n):\n",
        "        top_idx = np.argsort(A[i])[-top_k:]\n",
        "        for j in top_idx:\n",
        "            if i==j: continue\n",
        "            edges.append((i,j))\n",
        "            weights.append(A[i,j])\n",
        "    if len(edges)==0:\n",
        "        # fallback to complete graph (small channels case)\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if i!=j:\n",
        "                    edges.append((i,j)); weights.append(A[i,j] if i< A.shape[0] and j < A.shape[1] else 1.0)\n",
        "    edge_index = np.array(edges).T.astype(np.int64)\n",
        "    edge_attr = np.array(weights, dtype=np.float32)\n",
        "    # create Data\n",
        "    return Data(x=torch.tensor(x, dtype=torch.float),\n",
        "                edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
        "                edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
        "                y=torch.tensor([label], dtype=torch.float))\n",
        "\n",
        "# ----------------- Segmenting windows and labeling (uses your logic) -----------------\n",
        "def segment_data_with_times(raw, data, sf, seizure_events):\n",
        "    win_len, step = WIN_SECS*sf, STEP_SECS*sf\n",
        "    segs = []\n",
        "    rec_dur = data.shape[1] / sf\n",
        "    for start in range(0, data.shape[1]-win_len+1, step):\n",
        "        seg = data[:, start:start+win_len]\n",
        "        seg_start = start / sf\n",
        "        seg_end = (start + win_len) / sf\n",
        "        label = 0\n",
        "        is_ictal = False\n",
        "        for onset, dur in seizure_events:\n",
        "            seiz_start = onset\n",
        "            seiz_end = onset + dur\n",
        "            if not (seg_end <= seiz_start or seg_start >= seiz_end):\n",
        "                is_ictal = True\n",
        "            if (seiz_start - PRE_SECS) <= seg_end < seiz_start:\n",
        "                label = 1\n",
        "        if EXCLUDE_ICTAL and is_ictal:\n",
        "            continue\n",
        "        segs.append((seg, seg_start, seg_end, label))\n",
        "    return segs\n",
        "\n",
        "# ----------------- Build dataset from Drive recursively (keeps per-file grouping) -----------------\n",
        "def prepare_sequences(base_path, subject_subfolder=SUBJECT, verbose=True):\n",
        "    # find files\n",
        "    folder = os.path.join(base_path, subject_subfolder)\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.edf\")))\n",
        "    if verbose:\n",
        "        print(\"Found EDF files:\", len(files))\n",
        "    file_to_sequences = {}\n",
        "    all_sequences = []\n",
        "    for fpath in tqdm(files, desc=\"files\"):\n",
        "        try:\n",
        "            raw, data, sf = load_eeg(fpath)\n",
        "        except Exception as e:\n",
        "            print(\"Failed to read\", fpath, e); continue\n",
        "        seiz_events = read_seizure_events_from_summary(fpath)\n",
        "        segs = segment_data_with_times(raw, data, sf, seiz_events)\n",
        "        graphs_for_file = []\n",
        "        for seg, sstart, send, label in segs:\n",
        "            g = build_graph(seg, label, sf)\n",
        "            graphs_for_file.append((g, sstart, send, label))\n",
        "            all_sequences.append((fpath, g, sstart, send, label))\n",
        "        file_to_sequences[fpath] = graphs_for_file\n",
        "    # build time-ordered sequences per file (SEQ_LEN)\n",
        "    sequences = []; seq_meta = []\n",
        "    for fpath, g_list in file_to_sequences.items():\n",
        "        if len(g_list) < SEQ_LEN:\n",
        "            continue\n",
        "        g_list = sorted(g_list, key=lambda x: x[1])\n",
        "        graphs_only = [x[0] for x in g_list]\n",
        "        times = [(x[1], x[2], x[3]) for x in g_list]\n",
        "        for i in range(0, len(graphs_only) - SEQ_LEN + 1):\n",
        "            seq = graphs_only[i:i+SEQ_LEN]\n",
        "            label = times[i+SEQ_LEN-1][2]  # label of last window in seq\n",
        "            seq_start = times[i][0]; seq_end = times[i+SEQ_LEN-1][1]\n",
        "            sequences.append(seq)\n",
        "            seq_meta.append((fpath, seq_start, seq_end, label))\n",
        "    if verbose:\n",
        "        pos = sum(m[3] for m in seq_meta); neg = len(seq_meta)-pos\n",
        "        print(f\"Total sequences: {len(sequences)} | Pos: {pos} | Neg: {neg}\")\n",
        "    return sequences, seq_meta, file_to_sequences\n",
        "\n",
        "# ----------------- Create dataset & DataLoaders -----------------\n",
        "sequences, seq_meta, file_to_sequences = prepare_sequences(BASE_PATH, SUBJECT)\n",
        "if len(sequences) == 0:\n",
        "    raise RuntimeError(\"No sequences found — check BASE_PATH/SUBJECT and summary files.\")\n",
        "\n",
        "# Optionally dilate binary labels to reduce boundary sensitivity\n",
        "if LABEL_DILATION_WINDOWS > 0:\n",
        "    # convert seq_meta labels binary -> dilated\n",
        "    y = np.array([m[3] for m in seq_meta])\n",
        "    y = dilate_labels_binary(y, LABEL_DILATION_WINDOWS)\n",
        "    for i in range(len(seq_meta)):\n",
        "        f, s, e, _ = seq_meta[i]\n",
        "        seq_meta[i] = (f, s, e, int(y[i]))\n",
        "\n",
        "# split by file to avoid leakage\n",
        "unique_files = sorted(list(set([m[0] for m in seq_meta])))\n",
        "random.shuffle(unique_files)\n",
        "n_train_files = int(0.8 * len(unique_files)) if len(unique_files)>1 else 1\n",
        "train_files = set(unique_files[:n_train_files])\n",
        "test_files = set(unique_files[n_train_files:]) if n_train_files < len(unique_files) else set(unique_files[n_train_files:])\n",
        "\n",
        "train_seqs, train_meta, test_seqs, test_meta = [], [], [], []\n",
        "for seq, meta in zip(sequences, seq_meta):\n",
        "    if meta[0] in train_files:\n",
        "        train_seqs.append(seq); train_meta.append(meta)\n",
        "    else:\n",
        "        test_seqs.append(seq); test_meta.append(meta)\n",
        "\n",
        "print(\"Train sequences:\", len(train_seqs), \"Test sequences:\", len(test_seqs))\n",
        "\n",
        "# Dataset + collate\n",
        "class SeqDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, seqs, metas):\n",
        "        self.s, self.m = seqs, metas\n",
        "    def __len__(self): return len(self.s)\n",
        "    def __getitem__(self, i):\n",
        "        label = torch.tensor(self.m[i][3], dtype=torch.float)\n",
        "        return self.s[i], label\n",
        "\n",
        "def seq_collate(batch):\n",
        "    seq_len = len(batch[0][0])\n",
        "    timesteps = []\n",
        "    for t in range(seq_len):\n",
        "        graphs_t = [b[0][t] for b in batch]\n",
        "        timesteps.append(Batch.from_data_list(graphs_t))\n",
        "    labels = torch.stack([b[1] for b in batch])\n",
        "    return timesteps, labels\n",
        "\n",
        "train_ds = SeqDataset(train_seqs, train_meta)\n",
        "test_ds  = SeqDataset(test_seqs, test_meta)\n",
        "train_loader = TorchDataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=seq_collate)\n",
        "test_loader  = TorchDataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=seq_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_feats = train_seqs[0][0].x.shape[1]\n",
        "print(\"Input feature dim:\", in_feats)"
      ],
      "metadata": {
        "id": "NyglMT9oOK5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c23fdb-52b6-49f3-926d-f2e5c5e1290c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature dim: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Dynamic STGNN model (learns edge reweights) -----------------\n",
        "class DynamicSTGNN(nn.Module):\n",
        "    def __init__(self, in_feats, hidden=64, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.g1 = GCNConv(in_feats, hidden)\n",
        "        # edge updater maps concat(src, dst) features -> [0,1]\n",
        "        self.edge_updater = nn.Sequential(nn.Linear(hidden*2, 64),\n",
        "                                          nn.ReLU(),\n",
        "                                          nn.Linear(64,1),\n",
        "                                          nn.Sigmoid())\n",
        "        self.g2 = GCNConv(hidden, hidden)\n",
        "        self.gru = nn.GRU(hidden, hidden, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, out_dim)\n",
        "    def forward(self, timesteps):\n",
        "        # timesteps: list[Batch] length = SEQ_LEN\n",
        "        embeds = []\n",
        "        for bt in timesteps:\n",
        "            bt = bt.to(DEVICE)\n",
        "            x, ei = bt.x, bt.edge_index\n",
        "            ea = bt.edge_attr if hasattr(bt, \"edge_attr\") else None\n",
        "            # first conv uses precomputed edge weights if present\n",
        "            if ea is not None:\n",
        "                h = F.relu(self.g1(x, ei, edge_weight=ea))\n",
        "            else:\n",
        "                h = F.relu(self.g1(x, ei))\n",
        "            # dynamic edge weighting (learned)\n",
        "            src, dst = ei\n",
        "            # cat src/dst node embeddings\n",
        "            efeat = torch.cat([h[src], h[dst]], dim=1)\n",
        "            edge_w = self.edge_updater(efeat).squeeze()  # same size as num edges\n",
        "            # second conv uses learned edge weights\n",
        "            h = F.relu(self.g2(h, ei, edge_weight=edge_w))\n",
        "            g_emb = global_mean_pool(h, bt.batch)\n",
        "            embeds.append(g_emb.unsqueeze(1))\n",
        "        seq = torch.cat(embeds, dim=1)  # (B, SEQ_LEN, hidden)\n",
        "        out, _ = self.gru(seq)          # out: (B, SEQ_LEN, hidden)\n",
        "        logits = self.fc(out[:,-1,:])   # use last timestep embedding -> (B, 1)\n",
        "        return logits.squeeze(1)        # (B,)"
      ],
      "metadata": {
        "id": "DGLKQQkuFvnf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Training & evaluation -----------------\n",
        "\n",
        "# Compute input feature dimension\n",
        "in_feats = train_seqs[0][0].x.shape[1]\n",
        "print(\"Input feature dim:\", in_feats)\n",
        "\n",
        "# Initialize model\n",
        "model = DynamicSTGNN(in_feats).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "\n",
        "# ----------------- NEW SECTION: Class weight computation -----------------\n",
        "# Compute positive sample ratio to weight rare seizure events more\n",
        "num_pos = sum([m[-1] for m in train_meta])\n",
        "num_total = len(train_meta)\n",
        "pos_weight = torch.tensor([(num_total - num_pos) / (num_pos + 1e-6)]).to(DEVICE)\n",
        "print(f\"Using pos_weight = {pos_weight.item():.2f}\")\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ----------------- NEW SECTION: Label dilation -----------------\n",
        "# This can be placed inside your data preprocessing function before DataLoader creation\n",
        "# Expands seizure labels to include preictal regions, improving early sensitivity\n",
        "def dilate_labels(binary_labels, dilation=10):\n",
        "    import numpy as np\n",
        "    from scipy.ndimage import binary_dilation\n",
        "    return binary_dilation(binary_labels, iterations=dilation).astype(int)\n",
        "\n",
        "# Apply this during preprocessing before sequence extraction\n",
        "# Example: label = dilate_labels(label, dilation=15)\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for timesteps, labels in tqdm(train_loader, desc=\"train\"):\n",
        "        timesteps = [b.to(DEVICE) for b in timesteps]\n",
        "\n",
        "        # Small random channel dropout to improve robustness\n",
        "        for bt in timesteps:\n",
        "            if CHANNEL_DROPOUT_P > 0:\n",
        "                mask = (torch.rand(bt.x.shape[0], device=bt.x.device) > CHANNEL_DROPOUT_P).unsqueeze(1).float()\n",
        "                bt.x = bt.x * mask\n",
        "\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(timesteps)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def eval_model(loader):\n",
        "    model.eval()\n",
        "    ys, preds, probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for timesteps, labels in loader:\n",
        "            timesteps = [b.to(DEVICE) for b in timesteps]\n",
        "            labels = labels.to(DEVICE)\n",
        "            logits = model(timesteps)\n",
        "            prob = torch.sigmoid(logits)\n",
        "            ys.extend(labels.cpu().numpy().tolist())\n",
        "            probs.extend(prob.cpu().numpy().tolist())\n",
        "            preds.extend((prob.cpu().numpy() > 0.5).astype(int).tolist())\n",
        "    return np.array(ys), np.array(preds), np.array(probs)\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss = train_epoch()\n",
        "    y_true_train, y_pred_train, _ = eval_model(train_loader)\n",
        "    y_true_val, y_pred_val, _ = eval_model(test_loader)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch} | Train Loss: {tr_loss:.4f}\")\n",
        "    print(\"Train report:\")\n",
        "    print(classification_report(y_true_train, y_pred_train, digits=4))\n",
        "    print(\"Val report:\")\n",
        "    print(classification_report(y_true_val, y_pred_val, digits=4))\n",
        "\n",
        "# ----------------- Compute seizure-wise metrics -----------------\n",
        "test_files_set = set([m[0] for m in test_meta])\n",
        "seizures_by_file = {}\n",
        "for fpath in test_files_set:\n",
        "    try:\n",
        "        evts = read_seizure_events_from_summary(fpath)\n",
        "        seizures_by_file[fpath] = evts\n",
        "    except:\n",
        "        seizures_by_file[fpath] = []\n",
        "\n",
        "_, y_pred_all, _ = eval_model(test_loader)\n",
        "pred_by_file = defaultdict(list)\n",
        "for meta, pred in zip(test_meta, y_pred_all):\n",
        "    fpath, sstart, send, lab = meta\n",
        "    pred_by_file[fpath].append((sstart, send, int(pred)))\n",
        "\n",
        "detected = 0; total_seizures = 0; false_alarms = 0; interictal_total_seconds = 0.0\n",
        "for fpath in test_files_set:\n",
        "    evts = seizures_by_file.get(fpath, [])\n",
        "    try:\n",
        "        raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
        "        rec_dur = raw.n_times / raw.info['sfreq']\n",
        "    except:\n",
        "        rec_dur = 0.0\n",
        "    seiz_dur_sum = sum(d for _, d in evts)\n",
        "    interictal_total_seconds += max(0.0, rec_dur - seiz_dur_sum)\n",
        "\n",
        "    for onset, dur in evts:\n",
        "        total_seizures += 1\n",
        "        found = any(p == 1 and (onset - PRE_SECS) <= send < onset\n",
        "                    for sstart, send, p in pred_by_file.get(fpath, []))\n",
        "        if found: detected += 1\n",
        "\n",
        "    for sstart, send, p in pred_by_file.get(fpath, []):\n",
        "        if p == 1 and not any((onset - PRE_SECS) <= send < onset for onset, _ in evts):\n",
        "            false_alarms += 1\n",
        "\n",
        "sensitivity = detected / total_seizures if total_seizures > 0 else float('nan')\n",
        "\n",
        "print(f\"\\nSeizure-wise sensitivity: {sensitivity:.4f} ({detected}/{total_seizures})\")"
      ],
      "metadata": {
        "id": "NkV06Bk-FOzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3377a18a-ff14-4473-f1d2-e5f93529ad05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature dim: 9\n",
            "Using pos_weight = 59.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:20<00:00, 19.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 | Train Loss: 1.0990\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9980    0.5634    0.7202     22125\n",
            "         1.0     0.0347    0.9328    0.0669       372\n",
            "\n",
            "    accuracy                         0.5695     22497\n",
            "   macro avg     0.5163    0.7481    0.3935     22497\n",
            "weighted avg     0.9821    0.5695    0.7094     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9991    0.8477    0.9172      6370\n",
            "         1.0     0.0555    0.9194    0.1047        62\n",
            "\n",
            "    accuracy                         0.8484      6432\n",
            "   macro avg     0.5273    0.8835    0.5109      6432\n",
            "weighted avg     0.9900    0.8484    0.9094      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [04:37<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 | Train Loss: 0.9831\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9957    0.7077    0.8273     22125\n",
            "         1.0     0.0449    0.8172    0.0851       372\n",
            "\n",
            "    accuracy                         0.7095     22497\n",
            "   macro avg     0.5203    0.7624    0.4562     22497\n",
            "weighted avg     0.9800    0.7095    0.8150     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9980    0.9174    0.9560      6370\n",
            "         1.0     0.0868    0.8065    0.1567        62\n",
            "\n",
            "    accuracy                         0.9164      6432\n",
            "   macro avg     0.5424    0.8619    0.5564      6432\n",
            "weighted avg     0.9892    0.9164    0.9483      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [04:49<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 | Train Loss: 0.9652\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9971    0.6296    0.7718     22125\n",
            "         1.0     0.0389    0.8925    0.0746       372\n",
            "\n",
            "    accuracy                         0.6339     22497\n",
            "   macro avg     0.5180    0.7610    0.4232     22497\n",
            "weighted avg     0.9813    0.6339    0.7603     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9989    0.8854    0.9387      6370\n",
            "         1.0     0.0712    0.9032    0.1321        62\n",
            "\n",
            "    accuracy                         0.8856      6432\n",
            "   macro avg     0.5351    0.8943    0.5354      6432\n",
            "weighted avg     0.9900    0.8856    0.9310      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [04:50<00:00,  9.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 | Train Loss: 0.9319\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9961    0.7029    0.8242     22125\n",
            "         1.0     0.0452    0.8360    0.0857       372\n",
            "\n",
            "    accuracy                         0.7051     22497\n",
            "   macro avg     0.5206    0.7694    0.4549     22497\n",
            "weighted avg     0.9804    0.7051    0.8120     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9983    0.9119    0.9532      6370\n",
            "         1.0     0.0848    0.8387    0.1541        62\n",
            "\n",
            "    accuracy                         0.9112      6432\n",
            "   macro avg     0.5416    0.8753    0.5536      6432\n",
            "weighted avg     0.9895    0.9112    0.9455      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [03:35<00:00, 13.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 | Train Loss: 0.9290\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9986    0.5915    0.7430     22125\n",
            "         1.0     0.0376    0.9489    0.0723       372\n",
            "\n",
            "    accuracy                         0.5975     22497\n",
            "   macro avg     0.5181    0.7702    0.4076     22497\n",
            "weighted avg     0.9827    0.5975    0.7319     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9991    0.8545    0.9211      6370\n",
            "         1.0     0.0579    0.9194    0.1090        62\n",
            "\n",
            "    accuracy                         0.8551      6432\n",
            "   macro avg     0.5285    0.8869    0.5151      6432\n",
            "weighted avg     0.9900    0.8551    0.9133      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:21<00:00, 19.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 | Train Loss: 0.9284\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9972    0.6601    0.7944     22125\n",
            "         1.0     0.0422    0.8898    0.0805       372\n",
            "\n",
            "    accuracy                         0.6639     22497\n",
            "   macro avg     0.5197    0.7749    0.4374     22497\n",
            "weighted avg     0.9814    0.6639    0.7826     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9991    0.8970    0.9453      6370\n",
            "         1.0     0.0799    0.9194    0.1471        62\n",
            "\n",
            "    accuracy                         0.8972      6432\n",
            "   macro avg     0.5395    0.9082    0.5462      6432\n",
            "weighted avg     0.9903    0.8972    0.9376      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:30<00:00, 18.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 | Train Loss: 0.9115\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9982    0.6173    0.7628     22125\n",
            "         1.0     0.0395    0.9355    0.0758       372\n",
            "\n",
            "    accuracy                         0.6225     22497\n",
            "   macro avg     0.5189    0.7764    0.4193     22497\n",
            "weighted avg     0.9824    0.6225    0.7515     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9991    0.8786    0.9350      6370\n",
            "         1.0     0.0687    0.9194    0.1278        62\n",
            "\n",
            "    accuracy                         0.8790      6432\n",
            "   macro avg     0.5339    0.8990    0.5314      6432\n",
            "weighted avg     0.9901    0.8790    0.9272      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:29<00:00, 18.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 | Train Loss: 0.9094\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9946    0.7608    0.8621     22125\n",
            "         1.0     0.0503    0.7527    0.0942       372\n",
            "\n",
            "    accuracy                         0.7607     22497\n",
            "   macro avg     0.5224    0.7568    0.4782     22497\n",
            "weighted avg     0.9789    0.7607    0.8494     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9973    0.9345    0.9649      6370\n",
            "         1.0     0.0994    0.7419    0.1752        62\n",
            "\n",
            "    accuracy                         0.9327      6432\n",
            "   macro avg     0.5483    0.8382    0.5701      6432\n",
            "weighted avg     0.9887    0.9327    0.9573      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:19<00:00, 20.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 | Train Loss: 0.8906\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9971    0.6996    0.8222     22125\n",
            "         1.0     0.0469    0.8790    0.0890       372\n",
            "\n",
            "    accuracy                         0.7025     22497\n",
            "   macro avg     0.5220    0.7893    0.4556     22497\n",
            "weighted avg     0.9814    0.7025    0.8101     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9984    0.8992    0.9462      6370\n",
            "         1.0     0.0763    0.8548    0.1400        62\n",
            "\n",
            "    accuracy                         0.8988      6432\n",
            "   macro avg     0.5373    0.8770    0.5431      6432\n",
            "weighted avg     0.9895    0.8988    0.9385      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:19<00:00, 20.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 | Train Loss: 0.8917\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9981    0.6603    0.7948     22125\n",
            "         1.0     0.0438    0.9247    0.0836       372\n",
            "\n",
            "    accuracy                         0.6647     22497\n",
            "   macro avg     0.5209    0.7925    0.4392     22497\n",
            "weighted avg     0.9823    0.6647    0.7831     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9991    0.8903    0.9416      6370\n",
            "         1.0     0.0754    0.9194    0.1394        62\n",
            "\n",
            "    accuracy                         0.8905      6432\n",
            "   macro avg     0.5373    0.9048    0.5405      6432\n",
            "weighted avg     0.9902    0.8905    0.9338      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:23<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 | Train Loss: 0.8794\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9988    0.5873    0.7397     22125\n",
            "         1.0     0.0376    0.9597    0.0724       372\n",
            "\n",
            "    accuracy                         0.5935     22497\n",
            "   macro avg     0.5182    0.7735    0.4060     22497\n",
            "weighted avg     0.9830    0.5935    0.7286     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9994    0.8429    0.9145      6370\n",
            "         1.0     0.0557    0.9516    0.1052        62\n",
            "\n",
            "    accuracy                         0.8439      6432\n",
            "   macro avg     0.5276    0.8972    0.5098      6432\n",
            "weighted avg     0.9903    0.8439    0.9067      6432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 2813/2813 [02:29<00:00, 18.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 | Train Loss: 0.8781\n",
            "Train report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9958    0.7528    0.8574     22125\n",
            "         1.0     0.0522    0.8091    0.0980       372\n",
            "\n",
            "    accuracy                         0.7537     22497\n",
            "   macro avg     0.5240    0.7810    0.4777     22497\n",
            "weighted avg     0.9802    0.7537    0.8449     22497\n",
            "\n",
            "Val report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9974    0.9187    0.9564      6370\n",
            "         1.0     0.0832    0.7581    0.1499        62\n",
            "\n",
            "    accuracy                         0.9171      6432\n",
            "   macro avg     0.5403    0.8384    0.5532      6432\n",
            "weighted avg     0.9886    0.9171    0.9487      6432\n",
            "\n",
            "\n",
            "Seizure-wise sensitivity: 1.0000 (1/1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n",
            "/tmp/ipython-input-32810115.py:102: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(fpath, preload=False, verbose=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Save the current trained model (after 12 epochs)\n",
        "save_path = \"model_checkpoint_epoch12.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"✅ Model saved successfully at: {save_path}\")\n"
      ],
      "metadata": {
        "id": "CJjYoYA1IbxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd10d25e-ef0f-49a0-9285-d8fec4fc9629"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved successfully at: model_checkpoint_epoch12.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# --- Load previous checkpoint ---\n",
        "checkpoint_path = \"model_checkpoint_epoch12.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
        "\n",
        "if 'model_state_dict' in checkpoint:\n",
        "    print(\"✅ Detected structured checkpoint (contains model_state_dict).\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    start_epoch = checkpoint.get('epoch', 12)\n",
        "else:\n",
        "    print(\"⚠️ Detected direct state_dict checkpoint — loading directly into model.\")\n",
        "    model.load_state_dict(checkpoint)\n",
        "    start_epoch = 12\n",
        "\n",
        "# --- Optimizer, scheduler, and loss ---\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([59.48]).to(DEVICE))\n",
        "\n",
        "print(f\"✅ Loaded model from epoch {start_epoch} — ready to fine-tune\")\n",
        "\n",
        "# --- Fine-tune only on training data ---\n",
        "num_finetune_epochs = 3  # can increase to 5 if you want\n",
        "for epoch in range(start_epoch + 1, start_epoch + 1 + num_finetune_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        if isinstance(batch, list) or isinstance(batch, tuple):\n",
        "            timesteps, labels = batch\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected batch format: {type(batch)}\")\n",
        "\n",
        "        labels = labels.to(DEVICE).float()\n",
        "        preds = model(timesteps)  # model expects list[Batch]\n",
        "        loss = criterion(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    scheduler.step(avg_train_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- Save after every epoch ---\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "\n",
        "print(\"✅ Fine-tuning completed and checkpoint saved.\")\n"
      ],
      "metadata": {
        "id": "be4yr3k5ZHoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64694d9-365d-40ba-8686-0b92283e89db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Detected direct state_dict checkpoint — loading directly into model.\n",
            "✅ Loaded model from epoch 12 — ready to fine-tune\n",
            "Epoch 13 | Train Loss: 0.8463\n",
            "Epoch 14 | Train Loss: 0.8349\n",
            "Epoch 15 | Train Loss: 0.8287\n",
            "✅ Fine-tuning completed and checkpoint saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load checkpoint properly\n",
        "checkpoint = torch.load(\"model_checkpoint_epoch12.pth\", map_location=DEVICE)\n",
        "\n",
        "if 'model_state_dict' in checkpoint:\n",
        "    print(\"✅ Structured checkpoint detected — loading model weights...\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "else:\n",
        "    print(\"⚠️ Direct state_dict detected — loading directly...\")\n",
        "    model.load_state_dict(checkpoint)\n",
        "\n",
        "model.eval()\n",
        "print(\"✅ Model loaded successfully and ready for evaluation!\")\n"
      ],
      "metadata": {
        "id": "uvjcZz_-ZORL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e8dd39-1784-4c40-f790-7ad14dc81aad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Structured checkpoint detected — loading model weights...\n",
            "✅ Model loaded successfully and ready for evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "all_labels, all_preds = [], []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        timesteps, labels = batch\n",
        "        labels = labels.to(DEVICE).float()\n",
        "\n",
        "        outputs = model(timesteps)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, digits=4))\n"
      ],
      "metadata": {
        "id": "G7vzUzK_ej7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df202ec7-f585-4055-ffae-24b7de32c093"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[5633  737]\n",
            " [   8   54]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.9986    0.8843    0.9380      6370\n",
            "         1.0     0.0683    0.8710    0.1266        62\n",
            "\n",
            "    accuracy                         0.8842      6432\n",
            "   macro avg     0.5334    0.8776    0.5323      6432\n",
            "weighted avg     0.9896    0.8842    0.9302      6432\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# --- Key metrics ---\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # recall for seizure (positive)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "f1 = (2 * precision * sensitivity) / (precision + sensitivity + 1e-8)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nDetailed Metrics:\")\n",
        "print(f\"✅ Sensitivity (Recall for seizure): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity (Recall for non-seizure): {specificity:.4f}\")\n",
        "print(f\"🎯 Precision: {precision:.4f}\")\n",
        "print(f\"📈 F1-score: {f1:.4f}\")\n",
        "print(f\"Overall Accuracy: {(tp+tn)/(tp+tn+fp+fn):.4f}\")\n"
      ],
      "metadata": {
        "id": "5lySyVTAe19_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0fd885-ba69-4b80-c21a-1f7474282b71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[5633  737]\n",
            " [   8   54]]\n",
            "\n",
            "Detailed Metrics:\n",
            "✅ Sensitivity (Recall for seizure): 0.8710\n",
            "✅ Specificity (Recall for non-seizure): 0.8843\n",
            "🎯 Precision: 0.0683\n",
            "📈 F1-score: 0.1266\n",
            "Overall Accuracy: 0.8842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# Convert metadata to DataFrame\n",
        "meta_df = pd.DataFrame(seq_meta, columns=['file_path', 'start', 'end', 'label'])\n",
        "\n",
        "# Extract patient ID and EDF filename\n",
        "meta_df['patient_id'] = meta_df['file_path'].apply(lambda x: os.path.basename(os.path.dirname(x)))  # e.g., chb01\n",
        "meta_df['file_name'] = meta_df['file_path'].apply(lambda x: os.path.basename(x))\n",
        "\n",
        "# Ensure lengths match\n",
        "meta_df = meta_df.iloc[:len(all_preds)].copy()\n",
        "meta_df['pred'] = all_preds\n",
        "\n",
        "# Group by patient and compute seizure-level sensitivity per patient\n",
        "patient_sensitivity = {}\n",
        "total_detected = 0\n",
        "total_seizures = 0\n",
        "\n",
        "for patient, p_group in meta_df.groupby('patient_id'):\n",
        "    detected = 0\n",
        "    total = 0\n",
        "\n",
        "    for file, group in p_group.groupby('file_name'):\n",
        "        # Check if the file actually contains seizure labels\n",
        "        if group['label'].sum() > 0:\n",
        "            total += 1\n",
        "            # If any window in that file was predicted seizure\n",
        "            if group['pred'].sum() > 0:\n",
        "                detected += 1\n",
        "\n",
        "    if total > 0:\n",
        "        sensitivity = detected / total\n",
        "        patient_sensitivity[patient] = (detected, total, sensitivity)\n",
        "        total_detected += detected\n",
        "        total_seizures += total\n",
        "\n",
        "# 🧾 Print per-patient and overall stats\n",
        "print(\"📊 Seizure-level Sensitivity per Patient:\\n\")\n",
        "for p, (d, t, s) in patient_sensitivity.items():\n",
        "    print(f\"{p}: {d}/{t} = {s:.3f}\")\n",
        "\n",
        "if total_seizures > 0:\n",
        "    overall_sensitivity = total_detected / total_seizures\n",
        "    print(f\"\\n🌍 Overall Seizure Sensitivity Across All Patients: {total_detected}/{total_seizures} = {overall_sensitivity:.3f}\")\n",
        "else:\n",
        "    print(\"No seizure events found in the dataset.\")\n"
      ],
      "metadata": {
        "id": "lWsjK1srftRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388848b4-2af4-41bd-f211-3a92b1c1400f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Seizure-level Sensitivity per Patient:\n",
            "\n",
            "chb01: 2/2 = 1.000\n",
            "\n",
            "🌍 Overall Seizure Sensitivity Across All Patients: 2/2 = 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_meta[0]\n"
      ],
      "metadata": {
        "id": "sJUPZvh3gAhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba73fa8-37f6-4fec-f16a-815fafa826df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/chb_data/chb01/chb01_01.edf', 0.0, 25.0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "y_true_all = []\n",
        "y_prob_all = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for seq, lbl in test_loader:\n",
        "        seq = [bt.to(DEVICE) for bt in seq]\n",
        "        logits = model(seq)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()\n",
        "        y_prob_all.extend(probs)\n",
        "        y_true_all.extend(lbl.numpy())\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true_all, y_prob_all)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – Dynamic STGNN\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s_BMDXFMgPZw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "40786073-cd07-4b7d-b03f-d078c44e6412"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}